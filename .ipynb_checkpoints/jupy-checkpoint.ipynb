{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "212c2e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Robert Downey': 0, 'Shahrukh khan': 1}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Taking the current dir name\n",
    "BASE_DIR=os.path.dirname(\"C:\\\\Users\\\\vikas\\\\OneDrive\\\\Desktop\\\\VS code\\\\Face Recognition\\\\images\")\n",
    "# Taking the image dir\n",
    "image_dir=os.path.join(BASE_DIR,\"images\")\n",
    "\n",
    "#importing Face Classifier \n",
    "face_cascade=cv2.CascadeClassifier('data/haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "#Here comes the LBPHFace Recognizer for the training purpose\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.save(\"trainer2.yml\")\n",
    "\n",
    "current_id=0\n",
    "labels_id={}\n",
    "x_train=[]\n",
    "y_labels=[]\n",
    "\n",
    "for root,dirs,files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\"jfif\") or file.endswith(\"png\") or file.endswith(\"jpg\") or file.endswith(\"jpeg\"):\n",
    "            path=os.path.join(root,file)\n",
    "\n",
    "            label=os.path.basename(os.path.dirname(path))\n",
    "            #print(label,path) # printing each picture paths from the directory\n",
    "            \n",
    "            if label in labels_id:\n",
    "                pass\n",
    "            else:\n",
    "                labels_id[label]=current_id\n",
    "                current_id+=1\n",
    "            id_=labels_id[label]\n",
    "\n",
    "\n",
    "            pil_image=Image.open(path).convert(\"L\") # .convert() into grayscale\n",
    "            image_array=np.array(pil_image,'uint8') # image converted into numpy array \n",
    "            faces=face_cascade.detectMultiScale(image_array)\n",
    "\n",
    "            for (x,y,w,h) in faces:\n",
    "                roi=image_array[y:y+h,x:x+w]\n",
    "                x_train.append(roi)\n",
    "                y_labels.append(id_)\n",
    "\n",
    "print(labels_id)\n",
    "\n",
    "with open(\"labels.pickle\",\"wb\") as f:\n",
    "    pickle.dump(labels_id,f)\n",
    "\n",
    "recognizer.train(x_train,np.array(y_labels))\n",
    "recognizer.save(\"trainer2.yml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f900601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "Identity Unmatch\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#importing Face Classifier \n",
    "face_cascade=cv2.CascadeClassifier('data/haarcascade_frontalface_alt2.xml')\n",
    "recognizer=cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read(\"trainer2.yml\")\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    #Capture Frame by Frame\n",
    "    ret,frame=cap.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    #Detecting faces using cascade\n",
    "    faces=face_cascade.detectMultiScale(gray)\n",
    "\n",
    "    for(x,y,w,h) in faces:\n",
    "        roi_gray=gray[y:y+h,x:x+w]\n",
    "        roi_color=frame[y:y+h,x:x+w]\n",
    "        \n",
    "        #recognizer \n",
    "        id_,conf=recognizer.predict(roi_gray)\n",
    "        \n",
    "        if conf<=75 and conf>=45:\n",
    "            print(id_)\n",
    "        else:\n",
    "            print(\"Identity Unmatch\")\n",
    "            \n",
    "        img_item=\"my_image.png\"\n",
    "        cv2.imwrite(img_item,roi_gray)\n",
    "        \n",
    "        color=(255,0,0)\n",
    "        thick=2\n",
    "        width=x+w\n",
    "        height=y+h\n",
    "        cv2.rectangle(frame,(x,y),(width,height),color,thick)\n",
    "\n",
    "    #Display the resulting frame \n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(20) & 0xFF==ord('q'):\n",
    "        break\n",
    "\n",
    "#when everything done,release the capture \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f2b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
